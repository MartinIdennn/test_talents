# test_talents
# Конфиг: 
Python 3.11.5 \
LLM - GigaChat \ 
Библиотеки - Pandas, langchain, requests, json
# План проекта
1) Преобразование данных в удобный формат - Pandas DF
2) Перевод названий - LLM или ML перевод, например Yandex or Google
3) На основе названий генерация описания - LLM
4) Проверка описаний с помощью LLM
5) Преобразование данных в нужный формат - json
# Опишу вкратце здесь, но все же советую заглянуть в ipynb Блокнот 
На все промпты можно посмотреть в ipynb блокноте (как и вообще весь код), они разделены с examples \
К сожалению, из доступных LLM на данный момент - только GigaChat, зато безгранично доступный :) \
Изначально собирался переводить имена с помощью LLM, однако появились проблемы со структурированием ответов модельки (видно в блокноте), поэтому в итоге использовал ML Translate от Yandex. \
Однако, из-за того, что это блюда и инфы по многим нет (я даже поискал в интернете ради интереса, не нашел многие), более того даже Yandex Translate не все смог перевести, опять же скорее всего многие из названий просто остаются испанскими 
# Генерация описания
Моделька по-моему тоже не особо понимает, про какие блюда идет речь, опять же из-за того, что они редкие и в обучении вряд ли много фигурировали, возможно при использовании ChatGPT или DS ситуация бы поменялась\
Много менял промпт, так как Гигачат плохо структурировал свои ответы, пробовал добавлять в Examples больше примеров (примеры сначала искал в интернете, ничего не нашел и нагенерил), однако с 1 примером промпт работал лучше 
# Валидация ответов
В целом описания на все сгенерились, реализовал проверку этих описаний с помощью второго этапа, типа агента-оценщика, только не агент, а просто промпт, можно, конечно, сделать мультиагентную систему с многоступенчатой проверкой, но для теста сделал просто 2 промпта \
ГигаЧат все свои ответы одобрил, кроме тех, где он отказался (всего 2 раза), в реальном проекте использовал бы 2 разные LLM для ответов и оценки, но, для примера сделал на ГигаЧате \
Результат в menu_en.json

